---
title: 'Vibe Speccing: Vibe Coding That Actually Works'
date: '2025-06-11'
tags:
  [
    'ai',
    'llm',
    'Spec',
    'workflows',
    'cursor',
    'windsurf',
    'development',
    'requirements',
    'productivity',
    'claude',
    'chatgpt',
    'openai',
    'anthropic',
  ]
draft: false
summary: 'How I Learned to Stop Worrying and Love the Product Requirements Document - why writing Specs first transforms AI-assisted development from chaotic code generation into structured, resumable workflows.'
---

<h5 className="border-y py-4" style={{ textAlign: 'center', fontStyle: 'italic' }}>
  <span style={{ fontStyle: 'italic', fontFamily: 'KaTeX_Math' }}>
    "It doesn't matter how quickly you can create something if it's useless"
  </span>
</h5>

<div
  style={{
    padding: '1rem',
    borderColor: '#aaa',
    background: '#938ffa',
    color: 'white',
    borderRadius: '8px',
    borderWidth: '5px',
    marginBottom: '2rem',
    marginTop: '2rem',
  }}
>
  <strong>TL;DR:</strong> Make your AI write requirements before code. It takes 5 extra minutes and
  saves hours of confusion. Copy the cursor rules below and try it on your next feature.
</div>

## 0. Quick Start (2 minutes)

**Just want to try it? Here's the fastest path:**

<br />

<details>

<summary style={{cursor: 'pointer'}}>üëâ Expand for Quick Start Instructions</summary>
<div style={{paddingLeft: '10px'}}>

**1. Copy this into your Cursor settings**

<details>

<summary style={{ cursor: 'pointer' }}>üìã Copy These Instructions</summary>

```markdown
## Development Workflow: Spec ‚Üí Code

THESE INSTRUCTIONS ARE CRITICAL!

They dramatically improve the quality of the work you create.

### Phase 1: Requirements First

When asked to implement any feature or make changes, ALWAYS start by asking:
"Should I create a Spec for this task first?"

IFF user agrees:

- Create a markdown file in `.cursor/scopes/FeatureName.md`
- Interview the user to clarify:
- Purpose & user problem
- Success criteria
- Scope & constraints
- Technical considerations
- Out of scope items

### Phase 2: Review & Refine

After drafting the Spec:

- Present it to the user
- Ask: "Does this capture your intent? Any changes needed?"
- Iterate until user approves
- End with: "Spec looks good? Type 'GO!' when ready to implement"

### Phase 3: Implementation

ONLY after user types "GO!" or explicitly approves:

- Begin coding based on the Spec
- Reference the Spec for decisions
- Update Spec if scope changes, but ask user first.

### File Organization

\`\`\`

.cursor/
‚îú‚îÄ‚îÄ scopes/
‚îÇ ‚îú‚îÄ‚îÄ FeatureName.md # Shared/committed Specs
‚îÇ ‚îî‚îÄ‚îÄ .local/ # Git-ignored experimental Specs
‚îÇ ‚îî‚îÄ‚îÄ Experiment.md

\`\`\`

**Remember: Think first, ask clarifying questions, _then_ code. The Spec is your north star.**

(source: https://lukebechtel.com/blog/llm-Spec-code)
```

</details>

```
Settings ‚Üí Rules ‚Üí Create Rule ‚Üí Paste the rules below ‚Üí Enable "Always"
```

**2. Start a new chat and type:**

```
"Help me add user authentication to my app"
```

**3. Follow the AI Through Spec Creation**

The AI will:

- ‚ùì Ask smart questions you hadn't considered
- üìù Write a clear requirements document
- ‚úÖ Wait for your approval

**Example questions it might ask:**

- "Will users log in with email or username?"
- "Do you need password reset functionality?"
- "Should sessions expire?"

You're free to edit this for as long as you'd like.

The LLM won't write code until you say you want it!

**4. Authorize Code**
Once you're happy, you can authorize the LLM to go (just say "go!").

The LLM will then build exactly what you agreed on

**That's it!** You just experienced Vibe Speccing.

‚è±Ô∏è **Time invested:** 5 minutes writing requirements  
üí∞ **Time saved:** Hours of wrong implementations

<div style={{textAlign: 'center', marginTop: '20px'}}>
<button style={{padding: '10px 20px', fontSize: '16px', cursor: 'pointer'}}>
üëá Keep reading to understand why this works
</button>
</div>
</div>
</details>

<br />

If pasting cursorrules from random strangers makes you uncomfortable, read on.

## I. Vibe Coder's Lament

Consider the modern predicament: You sit before your IDE, cursor blinking expectantly. The task is clear enough in your mind: implement a widget. You open your AI Agent of choice, and begin typing:

> Create a widget that...

30 minutes later, you're ten modules deep, with 49 files changed, and have iterated through six separate widget architectures, each one replete with handlers for edge cases you'll never encounter and optimizations for scale you'll never reach.

You close the chat window. You open a new one.

> Let me be more specific...

<span style={{ fontSize: '2rem' }}>üòÆ‚Äçüí®</span>

Sound familiar?

LLMs will happily expand a vague prompt into paragraphs of plausible code. Hundreds of memes make fun of the low-quality "slop software" that comes from lazy prompting -- but even the best-intentioned programmers still run into issues where the AI spends a lot of time building features that didn't align with their original intentions.

> [@karpathy](https://x.com/karpathy/status/1915581920022585597):
> Noticing myself adopting a certain rhythm in AI-assisted coding (i.e. code I actually and professionally care about, contrast to vibe code).
>
> ...
>
> **_The emphasis is on keeping a very tight leash on this new over-eager junior intern savant with encyclopedic knowledge of software, but who also bullshits you all the time, has an over-abundance of courage and shows little to no taste for good code. And emphasis on being slow, defensive, careful, paranoid, and on always taking the inline learning opportunity, not delegating. Many of these stages are clunky and manual and aren't made explicit or super well supported yet in existing tools. We're still very early and so much can still be done on the UI/UX of AI assisted coding._**

There are many folk remedies for this; longer prompts, stricter system messages, chains / trees of thought, endless _"you are an expert"_ preambles. These remedies have their place. But they're all nuanced, flaky, and complicated to implement. The average developer just wants something fire-and-forget -- and who can blame them? AI was _supposed to be easier_!

Besides, these are all bandaids. The real problem, the _real_ reason that so much AI-generated software kinda sucks is much simpler: **_the AI doesn't understand the problem you're solving, because you didn't adequately explain the problem's context._**

What's funny is that this problem isn't really new. The same issues come up when delegating tasks to human workers, too. The way we solve this with humans, is to write a concise set of _requirements_. What is the objective? What determines success? What tools should we use to achieve the objective? How will we know when we're finished?

And indeed, with AI -- it turns out that this older, humbler practice is still the cure: **write the requirements first**. Give the AI a crisp spec, and you get crisp, consistent output; give it a vibe, and you get a vibe back.

**_"But requirements are hard to write!"_** -- you complain.

Ah yes, **_they used to be_**... until recently...

## II. The Modest Proposal

<img
  src="/static/images/vibe-speccing-diagram.png"
  alt="A diagram showing the vibe speccing workflow"
/>
<i>Don't worry -- it's even less complex than it seems</i>

(Spec === Requirements === Spec)

So... you should write requirements docs before coding.

I know what you're thinking: _"Ugh, great, more documentation. Just what I needed."_

But here's the thing - _you don't write the Spec; the LLM does._

Your job is to critique, tweak, and clarify.

And here's the best part: you don't even have to remember to do it. Just paste my cursor rules (below) once, and your AI will automatically ask to create a Spec before writing any code.

Make your LLM write requirements before code.

That's it. That's the whole trick.

**_The *first* thing you do with your LLM should be to write a Spec, not Code._**

### Workflow

<details style={{border: '1px solid white'}}>
<summary style={{cursor: 'pointer', padding: '10px'}}>(Click to expand): <strong style={{fontSize: '25px'}}>Complete Cursor Rules (Copy This!)</strong></summary>

```markdown
## Development Workflow: Spec ‚Üí Code

THESE INSTRUCTIONS ARE CRITICAL!

They dramatically improve the quality of the work you create.

### Phase 1: Requirements First

When asked to implement any feature or make changes, ALWAYS start by asking:
"Should I create a Spec for this task first?"

IFF user agrees:

- Create a markdown file in `.cursor/scopes/FeatureName.md`
- Interview the user to clarify:
- Purpose & user problem
- Success criteria
- Scope & constraints
- Technical considerations
- Out of scope items

### Phase 2: Review & Refine

After drafting the Spec:

- Present it to the user
- Ask: "Does this capture your intent? Any changes needed?"
- Iterate until user approves
- End with: "Spec looks good? Type 'GO!' when ready to implement"

### Phase 3: Implementation

ONLY after user types "GO!" or explicitly approves:

- Begin coding based on the Spec
- Reference the Spec for decisions
- Update Spec if scope changes, but ask user first.

### File Organization

\`\`\`

.cursor/
‚îú‚îÄ‚îÄ scopes/
‚îÇ ‚îú‚îÄ‚îÄ FeatureName.md # Shared/committed Specs
‚îÇ ‚îî‚îÄ‚îÄ .local/ # Git-ignored experimental Specs
‚îÇ ‚îî‚îÄ‚îÄ Experiment.md

\`\`\`

**Remember: Think first, ask clarifying questions, _then_ code. The Spec is your north star.**

(source: https://lukebechtel.com/blog/llm-Spec-code)
```

</details>

1. Setup Custom Instructions for your AI Code Helper of Choice (Cursor, Windsurf, Claude Code, etc)
2. Make sure the instructions are "Always Attached"
3. Start a New AI Chat
4. Let the AI guide you through Spec creation
5. ???
6. Profit

### Example

What does this do? Here's a before and after:

**BEFORE (Immediate Code Generation)**

<img
  src="/images/llm-immediate-code.png"
  alt="AI assistant immediately starting to make code changes for API route creation"
/>

**AFTER (Spec-First Approach)**

<img
  src="/images/llm-Spec-first.png"
  alt="AI assistant asking clarifying questions and offering to create a Spec before making changes"
/>

My original instructions kind of _sucked_, didn't they?

In the Spec-First approach, we account for this type of under-specified problem. The LLM will ask us follow up questions, and ensure it's building the right thing, before it jumps in.

The contrast is striking. In the first screenshot, the assistant immediately dives into implementation, spending 5 minutes generating code that may not match the user's actual needs. In the second, it pauses to understand requirements first.

The time difference is telling: 5 minutes of potentially wasted implementation versus 30 seconds of clarifying questions that lead to the right solution. The Spec-first approach doesn't just produce better code‚Äîit respects your time and cognitive load.

### Your First Spec

Try this right now:

1. Copy the cursor rules above
2. Ask your AI: "Help me create [your next feature]"
3. Watch as it asks clarifying questions you hadn't considered

Now you're programming at a higher level. You're creating _natural language evals_.

Even a simple "add dark mode" request turns into a set of deeper questions you may never have asked, letting you take finer-grained control:

- Toggle location: navbar vs settings?
- Persistence: localStorage or user preferences API?
- Scope: just UI or syntax highlighting too?

You can assert your control where you'd like it; anywhere you don't want to, you simply tell the LLM to use its best judgment.

### Benefits

Why do this? Doesn't this just take a lot of extra time on the front end?

Aren't we trying to _move fast & break things_?

Well, no. Slow is smooth, and smooth is fast.

_It doesn't matter how quickly you can create something if it's useless._

Here are the key problems I've noticed with traditional LLM workflows, and how a Spec-first approach solves them:

1. **Chat Drift ‚Üí Stable Documentation**

   - **Problem**: Exploratory Chat histories necessarily include the exploration and correction of many blind alleys. These turns of conversation would confuse anyone -- and LLMs are no exception.

   - **Solution**: A Spec document remains stable, even as the chat context changes. Reset the chat window. Change models. Switch IDEs. It doesn't matter; the Spec is just a document in your codebase, like any other file. You're providing structured, dense information that the LLM can parse efficiently ([Batarseh et al., 2021](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00445-7)).

2. **Solo Coding ‚Üí Team Sport**

   - **Problem**: LLM development is often a solo endeavor because chat histories are ephemeral and personal. You can't easily hand off work to a colleague or pick up where someone else left off without lengthy explanations.

   - **Solution**: With a Spec, suddenly it's not single-player anymore. You can close your chat, go to lunch, come back, and hand the same Spec to a completely fresh context window ‚Äî or to a human colleague. _The work persists beyond the ephemeral chat session._

3. **No Version Control ‚Üí Git-Tracked Requirements**

   - **Problem**: Git doesn't track your AI conversations. It can't diff your chat history. When requirements evolve or team members need context, there's no systematic way to track the evolution of your thinking.

   - **Solution**: Git can track `WidgetFeature.md`, and more importantly, it can track how `WidgetFeature.md` evolves as your understanding deepens. You can push up the git branch with the Spec and let another colleague begin work immediately, with full context about what needs to be built and why.

4. **Feature Creep ‚Üí Defined Scope**

   - **Problem**: Natural language can be very ambiguous. There's a reason that legalese exists. When you tell an LLM "make a search feature," it might reasonably assume you want fuzzy matching, autocomplete, search history, and real-time updates, or it might assume you want none of these.

   - **Solution**: When your Spec specifies "basic string matching on user names only," you skip the feature creep entirely. Structured requirements are less ambiguous than conversational requests.

5. **Lost Context ‚Üí Instant Resume**

   - **Problem**: Projects go off course and feel like they require too much effort to get back on track, leading to abandonment.

   - **Solution**: With Specs, you can return to a project after a week and understand immediately not just what you were building, but why you made specific architectural decisions.

6. **Blank Page Paralysis ‚Üí Structured Start**

   - **Problem**: That terrifying moment of not knowing how to start a feature or project.

   - **Solution**: The LLM becomes your documentation assistant first, your coding assistant second. It's much easier to critique a proposed Spec than to draft one from scratch.

7. **Token Waste ‚Üí Efficient Context**

   - **Problem**: Burning precious context tokens on exploratory conversation instead of focused implementation.

   - **Solution**: You're providing structured, dense information that the LLM can parse efficiently, leading to more focused and relevant responses.

## III. The Evidence

I have three sources of evidence that this is the most effective way to use LLMs -- personal anecdata, academic research, and industry examples.

### Personal Results

#### My Interview With the CTO

I recently had a fun interview with the CTO of a leading bay area AI Startup.

Part of the interview process was an open-ended real-world coding task, to assess how well I could use AI coding tools. (Which was _so much more fun and realistic_ than leetcode...)

I had 45 minutes to write a fairly complex webserver. Spending the first 5 minutes writing a Spec let me finish _20 minutes early_, with a _perfect implementation_.

Here's roughly how I spent my time:

- 5 minutes writing the Spec with the LLM.
- 10 minutes writing the code with the LLM.
- 5 minutes validating the code.
- 20 minutes asking the CTO questions.

Not bad, eh?

#### My Day-To-Day

In my own development:

- **Before Spec**: I would often spend 2-3 hours implementing something, then realizing I built the wrong thing
- **After Spec**: I spend about 10-20 minutes planning each feature, and 1 hour implementing correctly
- **Time saved**: I estimate that I have a ~60% reduction in feature development time, and I come out with a better result far more often.

In my personal experience, implementing my simple cursorrule has saved me **_literally days_** of back-and-forth with LLMs.

### Academic Evidence

Academia seems to be catching on -- Recent research on LLM-assisted development emphasizes that specifications are ["the missing link"](https://arxiv.org/html/2404.17842v1) in making LLM code generation reliable ([Pullum et al., 2020](https://sebokwiki.org/wiki/Verification_and_Validation_of_Systems_in_Which_AI_is_a_Key_Element)).

### Industry Validation

If you prefer an industry example, how about [OpenAI](https://openai.com)? They seem to have noticed this pattern too. Their [new Deep Research mode](https://openai.com/index/introducing-deep-research/) pauses to ask _clarifying questions_, tightening the problem definition before spending extra compute. Instead of torrenting answers, it builds understanding first. Imagine your coding assistant doing likewise: a quick interrogation that locks down scope, constraints, and must-haves, so the next burst of code is laser-focused instead of encyclopedic.

<img
  src="/images/chatgpt-clarification.png"
  alt="ChatGPT asking clarifying questions before proceeding"
/>

This differs from conventional AI-assisted development wisdom, which treats LLMs as code generators to be used when you're uncertain. "I need to implement X, let me ask Claude to write it." But this approach misunderstands both LLMs and good software development.

The magic isn't in avoiding the LLM until you have requirements. The magic is in using the LLM to help you discover what your requirements actually are.

As another example, Shopify's approach to their Auto Write feature began with a comprehensive Spec that aligned AI capabilities with merchant needs.

The pattern is becoming clear: successful AI features start with clear requirements, not clever prompts.

## VI. The Critique

### "gotta go fast"

A common objection, **"But I'm prototyping/in a hackathon/need to move fast!"**

Even for prototypes, 5 minutes of Spec saves hours of refactoring.

**\*It doesn't matter how quickly you can create something if it's useless.\*\***

### Garbage-in, Garbage-out

Of course, this does require you to give input. As Eugene Cherny warns in his LinkedIn article ["Product Managers: Beware GPT Specs"](https://www.linkedin.com/pulse/product-managers-beware-gpt-Specs-eugene-cherny-h3stc/), garbage in, garbage out still applies.

But that's precisely why the conversation matters. The LLM doesn't write your Spec in isolation; it interviews you, challenges assumptions, and iterates based on your feedback.

## VIII. Context Engineering

<div style={{marginBottom: '10px', gap: '10px', display: 'flex', flexDirection: 'column'}}>
<div style={{borderRadius: '8px', border: '1px solid gray', padding: '0px', overflow: 'hidden'}}>
    <img
        style={{margin: 0}}
        src="/static/images/tobi-context-engineering.png"
        alt="@tobi: I really like the term ‚Äúcontext engineering‚Äù over prompt engineering. It describes the core skill better: the art of providing all the context for the task to be plausibly solvable by the LLM."
        padding="0"
        margin="0"
    />
</div>

<div style={{borderRadius: '8px', border: '1px solid gray', padding: '0px', overflow: 'hidden',}}>
    <img
        style={{margin: 0}}
        src="/static/images/karpathy-context-engineering-short.png"
        alt='@karpathy: +1 for "context engineering" over "prompt engineering".'
        padding="0"
        margin="0"
    />
</div>
</div>
[source, @karpathy to @tobi on X](https://x.com/karpathy/status/1937902205765607626)

There's a growing understanding that "prompt engineering" isn't a sufficient term for what working with LLMs actually requires. As Andrej Karpathy recently noted in response to Tobias L√ºtke, "Context Engineering" better captures the sophisticated orchestration involved.

Karpathy Elaborates:

> People associate prompts with short task descriptions you'd give an LLM in your day-to-day use. When in every industrial-strength LLM app, context engineering is the delicate art and science of filling the context window with just the right information for the next step. Science because doing this right involves task descriptions and explanations, few shot examples, RAG, related (possibly multimodal) data, tools, state and history, compacting... Too little or of the wrong form and the LLM doesn't have the right context for optimal performance. Too much or too irrelevant and the LLM costs might go up and performance might come down. Doing this well is highly non-trivial. And art because of the guiding intuition around LLM psychology of people spirits.

[source, @karpathy to @tobi on X](https://x.com/karpathy/status/1937902205765607626)

Too little context and the LLM flails. Too much and it gets lost. It's about finding that sweet spot.

The Vibe Specs pattern helps you fall into the pit of success with context engineering.

When you're vibe coding without structure you're essentially playing context roulette -- sometimes you win, often you don't. But the multi-turn Spec construction process naturally guides you toward giving the LLM exactly what it needs.

Nothing more, nothing less.

## IX. Final Thoughts

In the age of AI-assisted development, every dev will become their own product manager.

The hardest part isn't writing the code anymore -- it's knowing _what code to write_. LLMs are incredibly powerful at the former. The Vibe Specs pattern ensures we don't abdicate responsibility for the latter.

Start your next feature with a Spec. Let your AI help you write it. Watch as your development velocity increases, your code quality improves, and‚Äîmost importantly‚Äîyour ability to context-switch without losing your mind returns.

The future of AI-assisted development isn't about better code generation. It's about better requirement articulation. LLM -> Spec -> Code. This is the way.

<div
  style={{
    padding: '1rem',
    borderColor: 'gray',
    borderRadius: '8px',
    borderWidth: '1px',
    marginBottom: '2rem',
    marginTop: '2rem',
  }}
>
  <h3 style={{ marginTop: 0 }}>Try It Now (5 Minutes)</h3>
  <ol style={{ textAlign: 'left', maxWidth: '400px' }}>
    <li>Copy the cursor rules</li>
    <li>Open your IDE</li>
    <li>Type: "Help me create [your next feature]"</li>
    <li>Watch the magic happen</li>
  </ol>
  <p style={{ marginTop: '1rem', fontWeight: 'bold' }}>LLM -> Spec -> Code. This is the way.</p>
</div>

---

## References & Further Reading

**Academic Research:**

- Dreossi, T., et al. (2024). ["Specifications: The missing link to making the development of LLM-based software more trustworthy"](https://arxiv.org/html/2404.17842v1). _arXiv preprint_.
- Pullum, L., Freeman, L., & Huang, C. (2020). ["Verification and Validation of Systems in Which AI is a Key Element"](https://sebokwiki.org/wiki/Verification_and_Validation_of_Systems_in_Which_AI_is_a_Key_Element). _Systems Engineering Body of Knowledge_.
- Batarseh, F. A., Freeman, L., & Huang, C. H. (2021). ["A survey on artificial intelligence assurance"](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-021-00445-7). _Journal of Big Data_, 8(1), 1-30.
- Hand, D. J., & Khan, S. (2020). ["Validating and Verifying AI Systems"](https://pmc.ncbi.nlm.nih.gov/articles/PMC7660449/). _Patterns_, 1(3), 100037.

**Industry Resources:**

- Cherny, E. (2024). ["Product Managers: Beware GPT Specs"](https://www.linkedin.com/pulse/product-managers-beware-gpt-Specs-eugene-cherny-h3stc/). _LinkedIn_.
- Downie (2024). ["Product requirement document generation using LLM task oriented"](https://gist.github.com/Dowwie/151d8efea738ea486ddec9208ddb3a19). _GitHub Gist_.
- Alward, R. (2024). ["Master the Blueprint: LLM Prompts for Perfect Product Requirements Documents (Spec)"](https://reeganalward.com/master-the-blueprint-llm-prompts-for-perfect-product-requirements-documents-Spec-192b23835462). _Medium_.
- Shoffstall, S. (2025). ["Revolutionizing Product Development: How AI is Transforming the Spec Process"](https://medium.com/@sean.shoffstall/revolutionizing-product-development-how-ai-is-transforming-the-Spec-process-4dbb66cba77d). _Medium_.

**Tools & Frameworks:**

- [Magical PM](https://www.magical.pm/) - AI-powered product management platform
- [GoGPractice.io](https://gopractice.io/skills/improving-product-quality-with-llm-guide/) - LLM-assisted product development guide
- [Mustafa Kapadia's Substack](https://mustafakapadia.substack.com/p/writing-product-requirements-with) - Writing product requirements with AI

---

<div className="flex items-center justify-center pt-4">
  <iframe
    src="https://lukebechtel.substack.com/embed"
    width="480"
    height="320"
    style={{ border: '1px solid #EEE', background: 'white' }}
    frameborder="0"
    scrolling="no"
  ></iframe>
</div>
