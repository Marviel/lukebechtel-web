---
title: 'AGQ: Survival Skills in the Age of AI'
date: '2023-04-11'
tags: ['gpt-4', 'agi', 'agq', 'large-language-models', 'ai', 'ml', 'alignment']
draft: false
summary: 'When AGI Comes, What will the role of humans be?'
---

<h3
  className="border-y py-4"
  style={{ textAlign: 'center', fontStyle: 'italic', fontFamily: 'KaTeX_Math' }}
>
  ‚ÄúWhen AGI comes, what will the role of humans be?‚Äù
</h3>

<AGQSectionHeader number={1} title={'"Setting"'} subHeader={['Why', 'This', 'Matters']} />

<ImageWithCaption
  caption={
    <span>
      "The Singularity"{' '}
      <a href="https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html">
        (original from Wait but Why)
      </a>
    </span>
  }
  src="/static/images/agq/wait-but-why-singularity-simple.png"
  alt={`"The Singularity" (original from Wait but Why)`}
/>

<hr />

<ImageWithCaption
  caption={
    <span>
      ChatGPT Time To 100M Users{' '}
      <a href="https://www.kylehailey.com/post/exponential-thinking">(original from Kyle Hailey)</a>
    </span>
  }
  src="/static/images/agq/chat-gpt-adoption-rate.png"
  alt={
    <span>
      "The Singularity{' '}
      <a href="https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html">
        (original from Wait but Why!)"
      </a>
    </span>
  }
/>

---

AI Progress is now measured in **_[days](https://twitter.com/bensbitesdaily/status/1642922715924365312?s=20)_**, not years.

Artificial General Intelligence (**AGI**) is either [here](https://openai.com/product/gpt-4) ([by some accounts](https://arxiv.org/pdf/2303.12712.pdf)) or [coming very soon](https://openai.com/blog/planning-for-agi-and-beyond).

Love it, or hate it; ignore it, or shun it, or embrace it:

### The [Age of AI](https://www.linkedin.com/pulse/age-ai-has-begun-bill-gates/?trackingId=SkZRGoC4RZhmP2FcgIgePg%3D%3D) is [here](https://openai.com/blog/planning-for-agi-and-beyond), yet **_nobody_** seems totally ready for it.

<br />
There are many forces which are set to play a part in the coming times. [Politics](https://davidrozado.substack.com/p/the-political-biases-of-gpt-4),
[economics](https://openai.com/research/gpts-are-gpts), sociology, information technology, and others
‚Äî yet **AGI** manages to be simultaneously the most ***unknown*** element, and the most ***transformative***
one.

<br />I have a growing mixture of concerns & hope about where I and my loved ones may fit in the new
shape of the world when this transformation is complete.

<br />
Perhaps you feel the same way.

<br />

**So let‚Äôs talk about it.**

---

<CustomAside
    icon={"‚è≥"}
    title={<span style={{textDecoration: 'underline', fontWeight: 'bold'}}>TL;DR for this Series</span>}
>

<b>Central Claim</b>

AIs are expected to be useful tools that reduce human cognitive load. AIs trained using state-of-the-art methods like Reinforcement Learning from Human Feedback (RLHF) are naturally selected for their resemblance to a specific subset of human minds. Many forces will conspire to push AGI adoption to occur in a fast, but not instantaneous, fashion ‚Äî with RLHF remaining as the primary teaching mechanism for AIs. As AGI is adopted gradually, hybrid organizations will begin to form, composed of Humans, AIs, and hybrids.

<br />

<b>
  Counterintuitively, this implies that for most of us, working and living with AIs will
  increasingly require *more* skills related to traditional Human Interaction, Psychology, &
  Organizational Psychology, than it will technical skills.
</b>

<br/>
<br/>
<b><u>
<agq>AGQ</agq> is introduced as a wrapper term for these skills, consisting of:

**_<agqsk>Self-Knowledge</agqsk>_**, **_<agqok>Other-Knowledge</agqok>_**, **_<agqgk>Group-Knowledge</agqgk>_**, & **_<agqwk>World-Knowledge</agqwk>._**

</u></b>

</CustomAside>

---

# What is **<agq>AGQ</agq>**?

It‚Äôs a term I made up, that stands for ‚Äú<agq>Ag</agq>ent <agq>Q</agq>uotient‚Äù

Am I authorized to **_make a term_**?

Nope! Sorry ü§ó

---

<aside>
‚≠ê <u><agq>AGQ: Agent Quotient</agq></u>

<agq>
  One‚Äôs ability to enact change in systems composed of ***<agq>Agents</agq>*** ‚Äî Humans, AIs, and
  ‚ÄúHybrids‚Äù / ‚ÄúCyborgs‚Äù.
</agq>

</aside>

---

<span style={{ color: 'gray' }}>
  *(We‚Äôll unpack this in detail, so don‚Äôt be concerned if there are some unfamiliar terms)*
</span>

<agq>AGQ</agq> can be thought of as a mixture of [EQ (Emotional Quotient)](https://en.wikipedia.org/wiki/Emotional_intelligence)
and [IQ (Intelligence Quotient)](https://en.wikipedia.org/wiki/Intelligence_quotient).

Just as EQ and IQ are different ([hard-to-measure accurately](https://en.wikipedia.org/wiki/Intelligence_quotient#Reliability_and_validity)) facets of the [idea of "G" -- or "General intelligence"](<https://en.wikipedia.org/wiki/G_factor_(psychometrics)>) -- "<agq>AGQ</agq>" is a wrapper-term around the ability to interact successfully with systems which are mixtures of human and artificial agents.

<br />
Why give this a new term?
<br />

The terms we have right now aren't quite enough.

**_IQ_** isn‚Äôt quite enough ‚Äî because it is focused primarily on pattern recognition, and makes no statements about an individual‚Äôs [‚Äútheory of mind‚Äù](https://en.wikipedia.org/wiki/Theory_of_mind).

And **_EQ_** isn‚Äôt quite enough ‚Äî because while it **does** cover ‚Äútheory of mind‚Äù, it has focused primarily on **_human minds_**, which will soon lose their monopoly on societal participation.

<br />

As we push (or are pushed) into this brave new world, we should have **some** concept of how to behave within it. When self-improving, it‚Äôs important to have a **_target_**.

Hence, **<agq>AGQ</agq>**.

## Mo‚Äô Minds, Mo‚Äô Problems

<ImageWithCaption
  caption={
    <span>
      GPT-4 Driven Agent Simulation,
      <a href="https://reverie.herokuapp.com/arXiv_Demo/#">screengrab from 'Reverie'</a>, paper:
      <a href="https://arxiv.org/pdf/2304.03442.pdf">
        Generative Agents: Interactive Simulacra of Human Behavior
      </a>
    </span>
  }
  src="/static/images/agq/gpt-sims.gif"
  alt={`"GPT-4 Driven Agent Simulationss`}
/>

Humans are all _different_.

<br />
This has presented us with opportunities and challenges for thousands of years.
<br />
However, ***compared to AI, humans are incredibly similar***.
<br />
Pick any two humans who seem different from each-other ‚Äî two political enemies, or two people from vastly
different walks-of-life. The differences between these human minds may seem stark. But the differences
between these two humans would seem ***miniscule***, if you weighed them against the differences between
either human and an AI system.

Not only will AI minds be different from our own ‚Äî AI minds will be **mutually** diverse, too. There will be many different kinds of AI minds, with different strengths and weaknesses. Some of the AI minds might even become more distinct from each-other than they are from us!

<br />
But these differences ***don‚Äôt mean we should just give up hope on understanding AI systems.***

There **_are_** similarities, however small, between how AI systems perceive the world, and how we do. They **_were_** designed in our image, after all. Further, when you study AI systems, you begin to realize that there are common ‚Äúsubsystems‚Äù which **_all_** intelligent beings must have ‚Äî human or not.

<br />
Thus despite our major differences, relating to AI will in some ways resemble how we relate to other
humans ‚Äî it‚Äôs a matter of understanding where we are alike, and where we differ.

In the Age of AI, we‚Äôll have to get comfortable interacting with **_all_** these types of minds, woven together in complex networks of **_multi-agent systems_**.

We'll all need to develop a strong [‚ÄúTheory of Mind‚Äù](https://en.wikipedia.org/wiki/Theory_of_mind), and learn how to apply the [Scientific Method](https://en.wikipedia.org/wiki/Scientific_method#:~:text=The%20process%20in%20the%20scientific,observations%20based%20on%20those%20predictions.)

<br />

Given this, the primary areas that I propose AGQ covers are as follows:

---

<aside>
üîë **The Key Domains of <agq>AGQ</agq>**

1. **<agqsk>Knowledge of Yourself ‚Äî _Self-Knowledge_</agqsk>**
2. **<agqok>Knowledge of Other Individuals ‚Äî _Other-Knowledge_</agqok>**
3. **<agqgk>Knowledge of Groups of Individuals ‚Äî _Group-Knowledge_</agqgk>**
4. **<agqwk>Knowledge of the World ‚Äî _World-Knowledge_</agqwk>**

</aside>

---

The former list can be broken down even further as:

---

<aside>
üßò **<agqsk>Self-Knowledge</agqsk>**

1. <agqsk>Noticing Patterns In your ‚ÄúInternal World‚Äù ‚Äî thoughts, drives, & emotions</agqsk>
2. <agqsk>
     Articulating Your Thoughts and Feelings <i>To Yourself</i>
   </agqsk>
3. <agqsk>Noticing Patterns in your Behavior</agqsk>
</aside>
<br/>
<aside>
üë§ **<agqok>Other-Knowledge</agqok>**

<agqok>
1. <agqok>Noticing Patterns In <i>Others‚Äô</i> Behavior</agqok>
2. <agqok>Using the Behavior of <i>Others</i> to Decipher <i>their</i> ‚ÄúInternal World‚Äùs (thoughts, drives, & emotions)</agqok>
3. Taking the perspective of others
4. Articulating your Thoughts and Feelings <i>To Others</i>
5. Coordinating your actions with Individuals
6. Directing & Being Directed by Other Individuals
</agqok>
</aside>
<br/>
<aside>
üë• **<agqgk>Group-Knowledge</agqgk>**

<agqgk>
1. Noticing Emergent Patterns in <i>Groups</i> of Individuals
2. Articulating your Thoughts and Feelings <i>To Groups</i>, without loss of information.
3. Coordinating your actions within Groups
4. Directing Groups
</agqgk>
</aside>
<br/>
<aside>
üåé **<agqwk>World-Knowledge</agqwk>**

<agqwk>
1. Ability to notice Patterns in your Environment.
2. Ability to make meaningful changes in the world.
</agqwk>
</aside>

---

To really cover this ground, and to do it **_well_** ‚Äî we‚Äôll need to explore a little bit of how our minds work, how AI minds work, how groups work, and how the world works.

We'll of course need to study State-of-the-Art AI systems, both to understand "who we're creating", but also as a means of understanding more about ourselves. (<i style={{color: 'gray'}}>& also because they're cool</i> ü§ì)

We'll need to learn some things about Psychology, both in individuals and in groups. We'll need to touch on topics around Cultural Development, Game Theory, & Decision Theory.

Taking all of the acquired knowledge and stretching it to the limit, we'll need to zoom out and look at the Social & Macroeconomic landscape -- to predict how the developments in AI will fit within the world we inhabit today, and exactly how much they'll change it.

<br />

Easy, right? üòâ

<br />

I won‚Äôt claim that I‚Äôll be able to do all of these justice, but at least it'll be a fun conversation.

<br />

<CustomAside
    icon={"‚ú®"}
    title={<span style={{textDecoration: 'underline', fontWeight: 'bold', fontStyle: 'italic'}}>What's Next</span>}
>
    <br/>
üé≠ In <u>**Part 2: ‚ÄúCharacters‚Äù**</u>, we‚Äôll go over some of the characters we should expect to see in the near future. We‚Äôll review some state-of-the-art research, and couple it with our intuitions about ***human minds*** to develop an intuition around ***AI minds.***

üï∏ In <u>**Part 3: ‚ÄúCyborganizations‚Äù**</u>, we‚Äôll talk about how these characters will interact to create emergent social structures ‚Äî from small groups, to major organizations.

üõ† In <u>**Parts 4-7: ‚ÄúSkills‚Äù**</u>, we‚Äôll explore the specific skills we should be investing in to prepare for the future we‚Äôve laid out: **_<agqsk>Self-Knowledge</agqsk>, <agqok>Other-Knowledge</agqok>, <agqgk>Group-Knowledge</agqgk>, <agqwk>World-Knowledge</agqwk>_**

üåå In <u>**Part 8: ‚ÄúEpilogue‚Äù**</u>, we‚Äôll talk about how this all ties together.

</CustomAside>

<br />
If you want to follow along ‚Äî subscribe to my newsletter below to be notified when the next post goes
live (should be in a day or two.)

<br />
‚Äî Luke
<br />

---

### WAIT

If you stayed to the end you're probably cool and I'd like to connect.

Please comment or subscribe below, follow me on [twitter](https://twitter.com/linkbechtel), or reach out through one of the other social links below.

<br />
***A L S O...*** -- I'm currently looking for engaging work around LLMs & ML Systems.

Check out my [projects](/projects), my [twitter](https://twitter.com/linkbechtel), my [linkedin](https://www.linkedin.com/in/luke-anthony-bechtel/), or my [github](https://github.com/Marviel) to see what I'm into.

<br />
Reach out :)
<br />
Stay curious
