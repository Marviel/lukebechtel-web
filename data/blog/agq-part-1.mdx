---
title: 'AGQ: Survival Skills in the Age of AI'
date: '2023-04-11'
tags: ['gpt-4', 'agi', 'agq', 'large-language-models', 'ai', 'ml', 'alignment']
draft: false
summary: 'When AGI Comes, What will the role of humans be?'
---

<h3
  className="border-y py-4"
  style={{ textAlign: 'center', fontStyle: 'italic', fontFamily: 'KaTeX_Math' }}
>
  â€œWhen AGI comes, what will the role of humans be?â€
</h3>

<AGQSectionHeader number={1} title={'"Setting"'} subHeader={['Why', 'This', 'Matters']} />

<ImageWithCaption
  caption={
    <span>
      "The Singularity"{' '}
      <a href="https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html">
        (original from Wait but Why)
      </a>
    </span>
  }
  src="/static/images/agq/wait-but-why-singularity-simple.png"
  alt={`"The Singularity" (original from Wait but Why)`}
/>

<hr />

<ImageWithCaption
  caption={
    <span>
      ChatGPT Time To 100M Users{' '}
      <a href="https://www.kylehailey.com/post/exponential-thinking">(original from Kyle Hailey)</a>
    </span>
  }
  src="/static/images/agq/chat-gpt-adoption-rate.png"
  alt={
    <span>
      "The Singularity{' '}
      <a href="https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html">
        (original from Wait but Why!)"
      </a>
    </span>
  }
/>

---

AI Progress is now measured in **_[days](https://twitter.com/bensbitesdaily/status/1642922715924365312?s=20)_**, not years.

Artificial General Intelligence (**AGI**) is either [here](https://openai.com/product/gpt-4) ([by some accounts](https://arxiv.org/pdf/2303.12712.pdf)) or [coming very soon](https://openai.com/blog/planning-for-agi-and-beyond).

Love it, or hate it; ignore it, or shun it, or embrace it:

### The [Age of AI](https://www.linkedin.com/pulse/age-ai-has-begun-bill-gates/?trackingId=SkZRGoC4RZhmP2FcgIgePg%3D%3D) is [here](https://openai.com/blog/planning-for-agi-and-beyond), yet **_nobody_** seems totally ready for it.

<br />
There are many forces which are set to play a part in the coming times. [Politics](https://davidrozado.substack.com/p/the-political-biases-of-gpt-4),
[economics](https://openai.com/research/gpts-are-gpts), sociology, information technology, and others
â€” yet **AGI** manages to be simultaneously the most ***unknown*** element, and the most ***transformative***
one.

<br />I have a growing mixture of concerns & hope about where I and my loved ones may fit in the new
shape of the world when this transformation is complete.

<br />
Perhaps you feel the same way.

<br />

**So letâ€™s talk about it.**

---

<CustomAside
    icon={"â³"}
    title={<span style={{textDecoration: 'underline', fontWeight: 'bold'}}>TL;DR for this Series</span>}
>

<b>Central Claim</b>

AIs are expected to be useful tools that reduce human cognitive load. AIs trained using state-of-the-art methods like Reinforcement Learning from Human Feedback (RLHF) are naturally selected for their resemblance to a specific subset of human minds. Many forces will conspire to push AGI adoption to occur in a fast, but not instantaneous, fashion â€” with RLHF remaining as the primary teaching mechanism for AIs. As AGI is adopted gradually, hybrid organizations will begin to form, composed of Humans, AIs, and hybrids.

<br />

<b>
  Counterintuitively, this implies that for most of us, working and living with AIs will
  increasingly require *more* skills related to traditional Human Interaction, Psychology, &
  Organizational Psychology, than it will technical skills.
</b>

<br/>
<br/>
<b><u>
<agq>AGQ</agq> is introduced as a wrapper term for these skills, consisting of:

**_<agqsk>Self-Knowledge</agqsk>_**, **_<agqok>Other-Knowledge</agqok>_**, **_<agqgk>Group-Knowledge</agqgk>_**, & **_<agqwk>World-Knowledge</agqwk>._**

</u></b>

</CustomAside>

---

# What is **<agq>AGQ</agq>**?

Itâ€™s a term I made up, that stands for â€œ<agq>Ag</agq>ent <agq>Q</agq>uotientâ€

Am I authorized to **_make a term_**?

Nope! Sorry ğŸ¤—

---

<aside>
â­ <u><agq>AGQ: Agent Quotient</agq></u>

<agq>
  Oneâ€™s ability to enact change in systems composed of ***<agq>Agents</agq>*** â€” Humans, AIs, and
  â€œHybridsâ€ / â€œCyborgsâ€.
</agq>

</aside>

---

<span style={{ color: 'gray' }}>
  *(Weâ€™ll unpack this in detail, so donâ€™t be concerned if there are some unfamiliar terms)*
</span>

<agq>AGQ</agq> can be thought of as a mixture of [EQ (Emotional Quotient)](https://en.wikipedia.org/wiki/Emotional_intelligence)
and [IQ (Intelligence Quotient)](https://en.wikipedia.org/wiki/Intelligence_quotient).

Just as EQ and IQ are different ([hard-to-measure accurately](https://en.wikipedia.org/wiki/Intelligence_quotient#Reliability_and_validity)) facets of the [idea of "G" -- or "General intelligence"](<https://en.wikipedia.org/wiki/G_factor_(psychometrics)>) -- "<agq>AGQ</agq>" is a wrapper-term around the ability to interact successfully with systems which are mixtures of human and artificial agents.

<br />
Why give this a new term?
<br />

The terms we have right now aren't quite enough.

**_IQ_** isnâ€™t quite enough â€” because it is focused primarily on pattern recognition, and makes no statements about an individualâ€™s [â€œtheory of mindâ€](https://en.wikipedia.org/wiki/Theory_of_mind).

And **_EQ_** isnâ€™t quite enough â€” because while it **does** cover â€œtheory of mindâ€, it has focused primarily on **_human minds_**, which will soon lose their monopoly on societal participation.

<br />

As we push (or are pushed) into this brave new world, we should have **some** concept of how to behave within it. When self-improving, itâ€™s important to have a **_target_**.

Hence, **<agq>AGQ</agq>**.

## Moâ€™ Minds, Moâ€™ Problems

<ImageWithCaption
  caption={
    <span>
      GPT-4 Driven Agent Simulation,
      <a href="https://reverie.herokuapp.com/arXiv_Demo/#">screengrab from 'Reverie'</a>, paper:
      <a href="https://arxiv.org/pdf/2304.03442.pdf">
        Generative Agents: Interactive Simulacra of Human Behavior
      </a>
    </span>
  }
  src="/static/images/agq/gpt-sims.gif"
  alt={`"GPT-4 Driven Agent Simulationss`}
/>

Humans are all _different_.

<br />
This has presented us with opportunities and challenges for thousands of years.
<br />
However, ***compared to AI, humans are incredibly similar***.
<br />
Pick any two humans who seem different from each-other â€” two political enemies, or two people from vastly
different walks-of-life. The differences between these human minds may seem stark. But the differences
between these two humans would seem ***miniscule***, if you weighed them against the differences between
either human and an AI system.

Not only will AI minds be different from our own â€” AI minds will be **mutually** diverse, too. There will be many different kinds of AI minds, with different strengths and weaknesses. Some of the AI minds might even become more distinct from each-other than they are from us!

<br />
But these differences ***donâ€™t mean we should just give up hope on understanding AI systems.***

There **_are_** similarities, however small, between how AI systems perceive the world, and how we do. They **_were_** designed in our image, after all. Further, when you study AI systems, you begin to realize that there are common â€œsubsystemsâ€ which **_all_** intelligent beings must have â€” human or not.

<br />
Thus despite our major differences, relating to AI will in some ways resemble how we relate to other
humans â€” itâ€™s a matter of understanding where we are alike, and where we differ.

In the Age of AI, weâ€™ll have to get comfortable interacting with **_all_** these types of minds, woven together in complex networks of **_multi-agent systems_**.

We'll all need to develop a strong [â€œTheory of Mindâ€](https://en.wikipedia.org/wiki/Theory_of_mind), and learn how to apply the [Scientific Method](https://en.wikipedia.org/wiki/Scientific_method#:~:text=The%20process%20in%20the%20scientific,observations%20based%20on%20those%20predictions.)

<br />

Given this, the primary areas that I propose AGQ covers are as follows:

---

<aside>
ğŸ”‘ **The Key Domains of <agq>AGQ</agq>**

1. **<agqsk>Knowledge of Yourself â€” _Self-Knowledge_</agqsk>**
2. **<agqok>Knowledge of Other Individuals â€” _Other-Knowledge_</agqok>**
3. **<agqgk>Knowledge of Groups of Individuals â€” _Group-Knowledge_</agqgk>**
4. **<agqwk>Knowledge of the World â€” _World-Knowledge_</agqwk>**

</aside>

---

The former list can be broken down even further as:

---

<aside>
ğŸ§˜ **<agqsk>Self-Knowledge</agqsk>**

1. <agqsk>Noticing Patterns In your â€œInternal Worldâ€ â€” thoughts, drives, & emotions</agqsk>
2. <agqsk>
     Articulating Your Thoughts and Feelings <i>To Yourself</i>
   </agqsk>
3. <agqsk>Noticing Patterns in your Behavior</agqsk>
</aside>
<br/>
<aside>
ğŸ‘¤ **<agqok>Other-Knowledge</agqok>**

<agqok>
1. <agqok>Noticing Patterns In <i>Othersâ€™</i> Behavior</agqok>
2. <agqok>Using the Behavior of <i>Others</i> to Decipher <i>their</i> â€œInternal Worldâ€s (thoughts, drives, & emotions)</agqok>
3. Taking the perspective of others
4. Articulating your Thoughts and Feelings <i>To Others</i>
5. Coordinating your actions with Individuals
6. Directing & Being Directed by Other Individuals
</agqok>
</aside>
<br/>
<aside>
ğŸ‘¥ **<agqgk>Group-Knowledge</agqgk>**

<agqgk>
1. Noticing Emergent Patterns in <i>Groups</i> of Individuals
2. Articulating your Thoughts and Feelings <i>To Groups</i>, without loss of information.
3. Coordinating your actions within Groups
4. Directing Groups
</agqgk>
</aside>
<br/>
<aside>
ğŸŒ **<agqwk>World-Knowledge</agqwk>**

<agqwk>
1. Ability to notice Patterns in your Environment.
2. Ability to make meaningful changes in the world.
</agqwk>
</aside>

---

To really cover this ground, and to do it **_well_** â€” weâ€™ll need to explore a little bit of how our minds work, how AI minds work, how groups work, and how the world works.

We'll of course need to study State-of-the-Art AI systems, both to understand "who we're creating", but also as a means of understanding more about ourselves. (<i style={{color: 'gray'}}>& also because they're cool</i> ğŸ¤“)

We'll need to learn some things about Psychology, both in individuals and in groups. We'll need to touch on topics around Cultural Development, Game Theory, & Decision Theory.

Taking all of the acquired knowledge and stretching it to the limit, we'll need to zoom out and look at the Social & Macroeconomic landscape -- to predict how the developments in AI will fit within the world we inhabit today, and exactly how much they'll change it.

<br />

Easy, right? ğŸ˜‰

<br />

I wonâ€™t claim that Iâ€™ll be able to do all of these justice, but at least it'll be a fun conversation.

<br />

<CustomAside
    icon={"âœ¨"}
    title={<span style={{textDecoration: 'underline', fontWeight: 'bold', fontStyle: 'italic'}}>What's Next</span>}
>
    <br/>
ğŸ­ In <u>**Part 2: â€œCharactersâ€**</u>, weâ€™ll go over some of the characters we should expect to see in the near future. Weâ€™ll review some state-of-the-art research, and couple it with our intuitions about ***human minds*** to develop an intuition around ***AI minds.***

ğŸ•¸ In <u>**Part 3: â€œCyborganizationsâ€**</u>, weâ€™ll talk about how these characters will interact to create emergent social structures â€” from small groups, to major organizations.

ğŸ›  In <u>**Parts 4-7: â€œSkillsâ€**</u>, weâ€™ll explore the specific skills we should be investing in to prepare for the future weâ€™ve laid out: **_<agqsk>Self-Knowledge</agqsk>, <agqok>Other-Knowledge</agqok>, <agqgk>Group-Knowledge</agqgk>, <agqwk>World-Knowledge</agqwk>_**

ğŸŒŒ In <u>**Part 8: â€œEpilogueâ€**</u>, weâ€™ll talk about how this all ties together.

</CustomAside>

<br />
If you want to follow along â€” subscribe to my newsletter below to be notified when the next post goes
live (should be in a day or two.)

<br />
â€” Luke
<br />

---

### WAIT

If you stayed to the end you're probably cool and I'd like to connect.

Please comment or subscribe below, follow me on [twitter](https://twitter.com/linkbechtel), or reach out through one of the other social links below.

<br />
***A L S O...*** -- I'm currently looking for engaging work around LLMs & ML Systems.

Check out my [projects](/projects), my [twitter](https://twitter.com/linkbechtel), my [linkedin](https://www.linkedin.com/in/luke-anthony-bechtel/), or my [github](https://github.com/Marviel) to see what I'm into.

<br />
Reach out :)
<br />
Stay curious
